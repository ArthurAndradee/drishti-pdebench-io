# Otimiza√ß√£o de Opera√ß√µes de E/S em Aplica√ß√µes Cient√≠ficas (SciML)

Este reposit√≥rio cont√©m o c√≥digo, os scripts de submiss√£o e as ferramentas de an√°lise de dados referentes ao artigo **"Otimiza√ß√£o de opera√ß√µes de E/S em aplica√ß√µes cient√≠ficas de aprendizado de m√°quina guiadas pelo Drishti"**. 

O estudo foca na mitiga√ß√£o de gargalos de Entrada/Sa√≠da (I/O) no treinamento de Redes Neurais Operat√≥rias (FNO) e U-Net, utilizando o benchmark [PDEBench](https://github.com/pdebench/PDEBench) em ambientes de Computa√ß√£o de Alto Desempenho (HPC).

## ‚ö†Ô∏è Aviso sobre o PDEBench e Modifica√ß√µes
Este reposit√≥rio inclui uma vers√£o local do **PDEBench**. 
* **Depend√™ncias Nativas:** Para informa√ß√µes detalhadas sobre as depend√™ncias originais da f√≠sica e matem√°tica do benchmark, consulte a [documenta√ß√£o oficial do PDEBench](https://github.com/pdebench/PDEBench).
* **Modifica√ß√µes Realizadas:** O c√≥digo do PDEBench contido neste reposit√≥rio **foi modificado** em rela√ß√£o ao original. As altera√ß√µes foram feitas especificamente nos *data loaders* (`pdebench/models/fno/` e `pdebench/models/unet/`) para:
  1. Instrumentar a fase de treinamento e extrair m√©tricas de execu√ß√£o usando o **Darshan DXT**.
  2. Implementar estrat√©gias de otimiza√ß√£o de E/S, incluindo **Alinhamento de Requisi√ß√µes (4KB)**, **MPI-IO Coletivo** e **Buffering**.

## üõ†Ô∏è Configura√ß√£o do Ambiente (Conda)

Para reproduzir este ambiente e executar os scripts de treinamento e an√°lise, voc√™ precisa ter o [Miniconda](https://docs.conda.io/en/latest/miniconda.html) ou Anaconda instalado.

1. Clone este reposit√≥rio:
   ```bash
   git clone [https://github.com/SEU_USUARIO/NOME_DO_REPOSITORIO.git](https://github.com/SEU_USUARIO/NOME_DO_REPOSITORIO.git)
   cd NOME_DO_REPOSITORIO
   ```
2. Recrie o ambiente Conda a partir do arquivo de requisitos:
   ```bash
   conda env create -f environment.yml
   conda activate nome_do_ambiente
   ```

# Estrutura de Scripts e Execu√ß√£o
O fluxo de trabalho deste reposit√≥rio √© dividido em execu√ß√£o no cluster (Slurm) e processamento de logs. Abaixo est√° a descri√ß√£o do que cada script principal faz:

1. Submiss√£o e Treinamento (Pasta jobs/)
    jobs/submit_workflow.sh: Script principal de orquestra√ß√£o. Ele dispara as rotinas de treinamento no gerenciador de filas Slurm, iterando sobre as varia√ß√µes f√≠sicas (ex: coeficientes do Advection e Burgers) e as estrat√©gias de E/S.
    jobs/train.sh: O job script do Slurm submetido aos n√≥s computacionais. Ele configura as vari√°veis de ambiente do Darshan (ex: DXT_ENABLE_IO_TRACE=1) e executa o c√≥digo Python modificado do PDEBench alocando recursos de GPU (ex: RTX 4090).
2. Extra√ß√£o e Processamento de Logs (Pasta scripts/)
    extract-darshan-logs.py: Interage com os arquivos .darshan gerados pela execu√ß√£o. Ele extrai os tra√ßos bin√°rios do DXT e os converte em um formato tabular leg√≠vel para an√°lise temporal e de vaz√£o (throughput).
    process-all-logs.py: Consolida os dados extra√≠dos de m√∫ltiplas rodadas do Darshan/Slurm. √ötil para varrer diret√≥rios de outputs e unificar os tempos de E/S e gargalos apontados.
    process-all-models.py: L√™ os resultados de predi√ß√£o gerados pelo PDEBench (m√©tricas num√©ricas como MSE, nRMSE e MaxError) para garantir a integridade convergencial da rede neural ap√≥s as otimiza√ß√µes de E/S. Gera os arquivos CSV (ex: Evaluation_Summary_Per_Optimization.csv).
3. Gera√ß√£o de Resultados para o Artigo (Pasta article/)
    article/create-graph.py: Consome os arquivos .csv consolidados e gera as figuras vetoriais em formato PDF (ex: comparacao-otimizacoes-FNO.pdf) utilizadas na se√ß√£o de Resultados do artigo.   
